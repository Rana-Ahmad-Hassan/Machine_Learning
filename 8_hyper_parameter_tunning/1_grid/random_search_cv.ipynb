{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "740e0a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d322ffe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa\n",
       "2           4.7          3.2           1.3          0.2  setosa\n",
       "3           4.6          3.1           1.5          0.2  setosa\n",
       "4           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = sns.load_dataset(\"iris\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5164c38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sepal_length    0\n",
       "sepal_width     0\n",
       "petal_length    0\n",
       "petal_width     0\n",
       "species         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17926f6f",
   "metadata": {},
   "source": [
    "Grid Search CV\n",
    "\n",
    "Grid Search CV is a hyperparameter tuning technique used in machine learning to find the optimal hyperparameters for a model. It's a type of exhaustive search that tries all possible combinations of hyperparameters and evaluates their performance using cross-validation.\n",
    "\n",
    "How Grid Search CV Works:\n",
    "\n",
    "1. Define Hyperparameter Grid: Define a grid of hyperparameters to search over.\n",
    "2. Cross-Validation: Split the data into training and validation sets, and use cross-validation to evaluate the model's performance.\n",
    "3. Model Evaluation: Train the model on the training set and evaluate its performance on the validation set for each combination of hyperparameters.\n",
    "4. Best Hyperparameters: Select the combination of hyperparameters that results in the best performance.\n",
    "\n",
    "Advantages:\n",
    "\n",
    "1. Exhaustive Search: Grid Search CV tries all possible combinations of hyperparameters, ensuring that the optimal solution is found.\n",
    "2. Cross-Validation: Grid Search CV uses cross-validation to evaluate the model's performance, reducing overfitting.\n",
    "3. Easy to Implement: Grid Search CV is a widely used technique, and many machine learning libraries (e.g., scikit-learn) provide built-in support.\n",
    "\n",
    "Disadvantages:\n",
    "\n",
    "1. Computationally Expensive: Grid Search CV can be computationally expensive, especially for large datasets or complex models.\n",
    "2. Curse of Dimensionality: As the number of hyperparameters increases, the number of possible combinations grows exponentially, making Grid Search CV less practical.\n",
    "\n",
    "Alternatives:\n",
    "\n",
    "1. Random Search: Randomly samples the hyperparameter space, rather than trying all possible combinations.\n",
    "2. Bayesian Optimization: Uses Bayesian inference to search for the optimal hyperparameters.\n",
    "\n",
    "Grid Search CV is a powerful technique for hyperparameter tuning, but it may not be the most efficient approach for large or complex problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b935831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 2}\n",
      "Best Cross-Validation Accuracy: 0.9333333333333333\n",
      "\n",
      "Accuracy Score: 0.9666666666666667\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        10\n",
      "  versicolor       1.00      0.90      0.95        10\n",
      "   virginica       0.91      1.00      0.95        10\n",
      "\n",
      "    accuracy                           0.97        30\n",
      "   macro avg       0.97      0.97      0.97        30\n",
      "weighted avg       0.97      0.97      0.97        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = data.drop(columns=\"species\")\n",
    "y = data[\"species\"]\n",
    "\n",
    "# Split (80% train, 20% test)\n",
    "train_X, test_X, train_Y, test_Y = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Define parameter grid (dictionary keys must be strings!)\n",
    "params = {\n",
    "    \"max_depth\": [2, 3, 4, 5, 6],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"criterion\": [\"gini\", \"entropy\"]\n",
    "}\n",
    "\n",
    "# Grid Search with Cross Validation\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=DecisionTreeClassifier(),\n",
    "    param_grid=params,\n",
    "    cv=5,   # 5-fold cross-validation\n",
    "    scoring=\"accuracy\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Train\n",
    "grid_search.fit(train_X, train_Y)\n",
    "\n",
    "# Best parameters\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Cross-Validation Accuracy:\", grid_search.best_score_)\n",
    "\n",
    "# Evaluate on test set\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(test_X)\n",
    "\n",
    "print(\"\\nAccuracy Score:\", accuracy_score(test_Y, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(test_Y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5fc6c1",
   "metadata": {},
   "source": [
    "Random Search CV\n",
    "\n",
    "Random Search CV is a hyperparameter tuning technique used in machine learning to find the optimal hyperparameters for a model. Unlike Grid Search CV, which tries all possible combinations of hyperparameters, Random Search CV randomly samples the hyperparameter space.\n",
    "\n",
    "How Random Search CV Works:\n",
    "\n",
    "1. Define Hyperparameter Distribution: Define a distribution for each hyperparameter (e.g., uniform, log-uniform).\n",
    "2. Random Sampling: Randomly sample the hyperparameter space, generating a set of hyperparameters.\n",
    "3. Model Evaluation: Train the model on the training set and evaluate its performance on the validation set using the sampled hyperparameters.\n",
    "4. Iteration: Repeat steps 2-3 for a specified number of iterations or until a stopping criterion is met.\n",
    "5. Best Hyperparameters: Select the combination of hyperparameters that results in the best performance.\n",
    "\n",
    "Advantages:\n",
    "\n",
    "1. Efficient: Random Search CV is often more efficient than Grid Search CV, especially for large hyperparameter spaces.\n",
    "2. Flexibility: Random Search CV can handle continuous and categorical hyperparameters.\n",
    "3. Less Prone to Overfitting: Random Search CV is less prone to overfitting, as it doesn't try all possible combinations.\n",
    "\n",
    "Disadvantages:\n",
    "\n",
    "1. No Guarantee of Optimal Solution: Random Search CV doesn't guarantee finding the optimal solution, as it relies on random sampling.\n",
    "2. May Miss Important Regions: Random Search CV may miss important regions of the hyperparameter space.\n",
    "\n",
    "When to Use:\n",
    "\n",
    "1. Large Hyperparameter Space: Random Search CV is suitable for large hyperparameter spaces where Grid Search CV is impractical.\n",
    "2. Limited Computational Resources: Random Search CV is a good option when computational resources are limited.\n",
    "\n",
    "Random Search CV is a useful technique for hyperparameter tuning, offering a good trade-off between efficiency and effectiveness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08949f6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'min_samples_split': 20, 'max_depth': 4, 'criterion': 'gini'}\n",
      "Best Cross-Validation Accuracy: 0.9333333333333333\n",
      "\n",
      "Accuracy Score: 0.9666666666666667\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        10\n",
      "  versicolor       1.00      0.90      0.95        10\n",
      "   virginica       0.91      1.00      0.95        10\n",
      "\n",
      "    accuracy                           0.97        30\n",
      "   macro avg       0.97      0.97      0.97        30\n",
      "weighted avg       0.97      0.97      0.97        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = data.drop(columns=\"species\")\n",
    "y = data[\"species\"]\n",
    "\n",
    "# Split (80% train, 20% test)\n",
    "train_X, test_X, train_Y, test_Y = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Define parameter distribution\n",
    "param_dist = {\n",
    "    \"max_depth\": [2, 3, 4, 5, 6],\n",
    "    \"min_samples_split\": [2, 5, 10, 20, 50],\n",
    "    \"criterion\": [\"gini\", \"entropy\"]\n",
    "}\n",
    "\n",
    "# Randomized Search with Cross Validation\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=DecisionTreeClassifier(),\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=10,              # number of random combinations to try\n",
    "    cv=5,                   # 5-fold CV\n",
    "    scoring=\"accuracy\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Train\n",
    "random_search.fit(train_X, train_Y)\n",
    "\n",
    "# Best parameters\n",
    "print(\"Best Parameters:\", random_search.best_params_)\n",
    "print(\"Best Cross-Validation Accuracy:\", random_search.best_score_)\n",
    "\n",
    "# Evaluate on test set\n",
    "best_model = random_search.best_estimator_\n",
    "y_pred = best_model.predict(test_X)\n",
    "\n",
    "print(\"\\nAccuracy Score:\", accuracy_score(test_Y, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(test_Y, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
